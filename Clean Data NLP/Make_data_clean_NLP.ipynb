{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import unicodedata\n",
        "import regex as re"
      ],
      "metadata": {
        "id": "qX95iX2KhV18"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('stopword.txt', 'r' , encoding='utf-8') as f:\n",
        "    stopwords = f.read().splitlines()\n",
        "    stopwords = [i for i in stopwords if i.find(\" \")==-1]\n",
        "bang_nguyen_am= [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
        "\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
        "nguyen_am_to_ids = {}\n",
        "\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
        "\n",
        "# Chuẩn hóa unicode \n",
        "# Có 2 loại unicode : unicode tổ hơp và unicode dựng sẵn, điêu này dẫn tới việc 2 từ giống nhau sẽ bị coi là khác nhau \n",
        "# Chuẩn hóa tất cả về 1 loại là unicode dựng sẵn\n",
        "def chuan_hoa_unicode(text):\n",
        "\ttext = unicodedata.normalize('NFC', text)\n",
        "\treturn text\n",
        "\n",
        "# Có 2 kiểu gõ dấu ở Tiếng Việt, ví dụ như là : òa hoặc oà (ta gọi lần lượt là chuẩn 1 và 2). Mặc dù kiểu gõ chữ sau ít \n",
        "#phổ biến hơn tuy nhiên vẫn cần phải chuẩn hóa tránh việc một số văn bản vẫn sử dụng kiểu gõ dấu thứ 2.\n",
        "\"\"\"\n",
        "\tHàm này xử lý chuẩn hóa từng từ một, sau khi chuẩn hóa từng từ thì ta sẽ đi chuân hóa từng câu sau \n",
        "\t\"\"\" \n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        " \n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9:  # check qu\n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5:  # check gi\n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        " \n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  # ê, ơ\n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            # for index2 in nguyen_am_index:\n",
        "            #     if index2 != index:\n",
        "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
        "            #         chars[index2] = bang_nguyen_am[x][0]\n",
        "            return ''.join(chars)\n",
        " \n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
        "        else:\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
        "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
        "    return ''.join(chars)\n",
        "\n",
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True\n",
        "\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    \"\"\"\n",
        "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        # print(cw)\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Tách từ tiếng việt, từ tiếng việt không giống như tiếng anh, tách từ tiếng anh ta chỉ cần tách bằng khoảng trắng\n",
        "# Tuy nhiên từ tiếng Việt có cả từ đơn lẫn từ ghép nên tách từ tiêng Việt sẽ phúc tạp hơn \n",
        "# Project sử dung thu viện pyvi (xem mã nguồn tại : https://github.com/trungtv/pyvi) để phục vụ bài toán con tách từ Tiếng Việt \n",
        "# def tach_tu_tieng_viet(text):\n",
        "# \ttext = ViTokenizer.tokenize(text)\n",
        "# \treturn text\n",
        "\n",
        "# Đưa về chữ viết thường \n",
        "def get_lower(text):\n",
        "        return text.lower().strip()\n",
        "\n",
        "# Xóa đi các dấu cách thừa, các từ không cần thiết cho việc phân loại vẳn bản \n",
        "def chuan_hoa_cau(text):\n",
        "\ttext = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',text)\n",
        "\ttext = re.sub(r'\\s+', ' ', text).strip()\n",
        "\treturn text\n",
        "\n",
        "def remove_tag (text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'',text)\n",
        "\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'http\\S+')\n",
        "    return pattern.sub(r'',text)\n",
        "\n",
        "def remove_punc(text):\n",
        "    exclude = string.punctuation\n",
        "    for char in exclude:\n",
        "        text = text.replace(char,'')\n",
        "    return text\n",
        "\n",
        "def remove_stopW(text):\n",
        "    new_text=[]\n",
        "    for word in text.split():\n",
        "        if word in stopwords:\n",
        "            new_text.append('')\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    x = [i for i in new_text if i != '']\n",
        "    new_text.clear()\n",
        "    return \" \".join(x)\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                        u\"\\U0001F600-\\U0001F64F\" \n",
        "                        u\"\\U0001F300-\\U0001F5FF\"  \n",
        "                        u\"\\U0001F680-\\U0001F6FF\"  \n",
        "                        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "                        u\"\\U00002702-\\U000027B0\"\n",
        "                        u\"\\U000024C2-\\U0001F251\"\n",
        "                        \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def clean_data(text):\n",
        "    text = get_lower(text)\n",
        "    text = remove_tag(text)\n",
        "    text = remove_url(text)\n",
        "    text = remove_stopW(text)\n",
        "    text = remove_emoji(text)\n",
        "    text = remove_punc(text)\n",
        "    text = chuan_hoa_unicode(text)\n",
        "    text = chuan_hoa_dau_cau_tieng_viet(text)\n",
        "    # text = tach_tu_tieng_viet(text)\n",
        "    text = chuan_hoa_cau(text)\n",
        "\n",
        "\n",
        "    return text\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     file = open(\"test.txt\", \"r\", encoding=\"utf-8\")\n",
        "#     data = file.read()\n",
        "#     data = tien_xu_li(data)\n",
        "#     print(\"Ví dụ : \\n\")\n",
        "#     print(data)"
      ],
      "metadata": {
        "id": "FPoUdICPhIi2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['ks đẹp, đối diện biển, buffet sáng ngon, nhân viên vô cùng ưng ý, thân thiện.',\n",
        "        'Đồ ăn hơi ít món nhưng ngon.',\n",
        "        'qá đáng']"
      ],
      "metadata": {
        "id": "FjV7WgPVhsne"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = []\n",
        "for i in text:\n",
        "    clean_text.append(clean_data(i))\n",
        "clean_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL6Xg5uohdwi",
        "outputId": "12a93d02-895b-46d2-81a1-d1fb47ad5722"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ks đẹp đối diện biển buffet sáng ngon nhân viên vô ưng ý thân thiện',\n",
              " 'đồ ăn hơi ít món ngon',\n",
              " 'qá đáng']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_annotatation(text):\n",
        "\tkhach_san = \"\\bkhach san ?|\\bksan ?|\\bks ?\"\n",
        "\treturn re.sub(\"\\bnv ?\", \"nhân viên\",re.sub(khach_san, \"khách sạn\", text))"
      ],
      "metadata": {
        "id": "GdTKcF6no8vZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_text = normalize_annotatation(\"ks đẹp, đối diện biển, buffet sáng ngon, nhân viên vô cùng ưng ý, thân thiện.\")\n",
        "print(normalized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2sXRXMGo95Q",
        "outputId": "e93f3ff6-a910-4d1c-8021-5587555a1a0f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ks đẹp, đối diện biển, buffet sáng ngon, nhân viên vô cùng ưng ý, thân thiện.\n"
          ]
        }
      ]
    }
  ]
}